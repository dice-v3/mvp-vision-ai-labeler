# Platform íŒ€ - Annotation íŒŒì¼ í˜•ì‹ ê°€ì´ë“œ

**ì‘ì„±ì¼**: 2025-11-30
**Phase**: 16.6 (Image Storage Information)
**ëŒ€ìƒ**: Platform Backend ê°œë°œíŒ€

---

## ğŸ“‹ ê°œìš”

Labelerê°€ exportí•˜ëŠ” annotation íŒŒì¼ì—ëŠ” **storage_info** ì„¹ì…˜ì´ í¬í•¨ë˜ì–´ ìˆì–´,
Platform íŒ€ì´ ì´ë¯¸ì§€ íŒŒì¼ì˜ S3/R2 ìœ„ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## ğŸ—‚ï¸ Annotation íŒŒì¼ í˜•ì‹

### DICE í˜•ì‹ (ê¶Œì¥)

```json
{
  "format_version": "1.0",
  "dataset_id": "ds_c75023ca76d7448b",
  "dataset_name": "mvtec-ad",
  "task_type": "object_detection",

  // â† Phase 16.6: ì´ë¯¸ì§€ ì €ì¥ ìœ„ì¹˜ ì •ë³´
  "storage_info": {
    "storage_type": "s3",                              // ë˜ëŠ” "r2"
    "bucket": "training-datasets",                     // S3/R2 ë²„í‚· ì´ë¦„
    "image_root": "datasets/ds_c75023ca76d7448b/images/"  // ì´ë¯¸ì§€ root ê²½ë¡œ
  },

  "classes": [
    {"id": 0, "name": "defect", "color": "#FF0000"}
  ],

  "images": [
    {
      "id": 1,
      "file_name": "zipper/squeezed_teeth/000.png",  // ìƒëŒ€ ê²½ë¡œ
      "width": 1024,
      "height": 1024,
      "split": "train",
      "annotations": [...]
    }
  ],

  "statistics": {...}
}
```

### COCO í˜•ì‹

```json
{
  "info": {...},
  "licenses": [...],

  // â† Phase 16.6: ì´ë¯¸ì§€ ì €ì¥ ìœ„ì¹˜ ì •ë³´
  "storage_info": {
    "storage_type": "s3",
    "bucket": "training-datasets",
    "image_root": "datasets/ds_c75023ca76d7448b/images/"
  },

  "images": [
    {
      "id": 1,
      "file_name": "zipper/squeezed_teeth/000.png",
      "width": 1024,
      "height": 1024
    }
  ],

  "annotations": [...],
  "categories": [...]
}
```

---

## ğŸ” storage_info í•„ë“œ ì„¤ëª…

| í•„ë“œ | íƒ€ì… | ì„¤ëª… | ì˜ˆì‹œ |
|------|------|------|------|
| `storage_type` | string | ìŠ¤í† ë¦¬ì§€ íƒ€ì… | `"s3"`, `"r2"` |
| `bucket` | string | S3/R2 ë²„í‚· ì´ë¦„ | `"training-datasets"` |
| `image_root` | string | ì´ë¯¸ì§€ íŒŒì¼ë“¤ì˜ root prefix | `"datasets/ds_c75023ca76d7448b/images/"` |

---

## ğŸ’¡ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë°©ë²•

### Python ì˜ˆì‹œ (boto3 ì‚¬ìš©)

```python
import json
import boto3
from pathlib import Path

# 1. Annotation íŒŒì¼ íŒŒì‹±
with open('annotations.json', 'r') as f:
    annotation = json.load(f)

storage_info = annotation['storage_info']
print(f"Bucket: {storage_info['bucket']}")
print(f"Image Root: {storage_info['image_root']}")

# 2. S3 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
s3_client = boto3.client(
    's3',
    endpoint_url='https://your-r2-endpoint.r2.cloudflarestorage.com',  # R2 ì‚¬ìš© ì‹œ
    aws_access_key_id='YOUR_ACCESS_KEY',
    aws_secret_access_key='YOUR_SECRET_KEY'
)

# 3. ê° ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
for image in annotation['images']:
    # Full S3 key êµ¬ì„±
    s3_key = storage_info['image_root'] + image['file_name']
    # ì˜ˆ: "datasets/ds_c75023ca76d7448b/images/zipper/squeezed_teeth/000.png"

    # ë¡œì»¬ ê²½ë¡œ
    local_path = Path('dataset') / image['file_name']
    local_path.parent.mkdir(parents=True, exist_ok=True)

    # ë‹¤ìš´ë¡œë“œ
    print(f"Downloading {s3_key} -> {local_path}")
    s3_client.download_file(
        Bucket=storage_info['bucket'],
        Key=s3_key,
        Filename=str(local_path)
    )

print(f"Downloaded {len(annotation['images'])} images")
```

### Python ì˜ˆì‹œ (ê°„ë‹¨í•œ í•¨ìˆ˜)

```python
def download_dataset_images(annotation_path: str, output_dir: str):
    """
    Annotation íŒŒì¼ì—ì„œ storage_infoë¥¼ ì½ê³  ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œ.

    Args:
        annotation_path: Annotation JSON íŒŒì¼ ê²½ë¡œ
        output_dir: ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  ë¡œì»¬ ë””ë ‰í† ë¦¬
    """
    import json
    import boto3
    from pathlib import Path

    # Annotation íŒŒì¼ ë¡œë“œ
    with open(annotation_path, 'r') as f:
        data = json.load(f)

    storage_info = data['storage_info']

    # S3 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (í™˜ê²½ë³€ìˆ˜ì—ì„œ credentials ì½ìŒ)
    s3 = boto3.client('s3')

    # ê° ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
    for img in data['images']:
        s3_key = storage_info['image_root'] + img['file_name']
        local_file = Path(output_dir) / img['file_name']
        local_file.parent.mkdir(parents=True, exist_ok=True)

        s3.download_file(
            Bucket=storage_info['bucket'],
            Key=s3_key,
            Filename=str(local_file)
        )

    return len(data['images'])


# ì‚¬ìš© ì˜ˆì‹œ
num_images = download_dataset_images(
    annotation_path='annotations.json',
    output_dir='/tmp/dataset'
)
print(f"Downloaded {num_images} images")
```

---

## ğŸ“‚ ë””ë ‰í† ë¦¬ êµ¬ì¡°

### S3/R2 ë²„í‚· êµ¬ì¡°

```
training-datasets/
â””â”€â”€ datasets/
    â””â”€â”€ ds_c75023ca76d7448b/
        â””â”€â”€ images/                           â† storage_info.image_root
            â”œâ”€â”€ zipper/
            â”‚   â”œâ”€â”€ squeezed_teeth/
            â”‚   â”‚   â”œâ”€â”€ 000.png              â† image.file_name
            â”‚   â”‚   â”œâ”€â”€ 001.png
            â”‚   â”‚   â””â”€â”€ ...
            â”‚   â””â”€â”€ thread/
            â”‚       â”œâ”€â”€ 000.png
            â”‚       â””â”€â”€ ...
            â””â”€â”€ ...
```

### ë‹¤ìš´ë¡œë“œ í›„ ë¡œì»¬ êµ¬ì¡°

```
/tmp/dataset/
â”œâ”€â”€ zipper/
â”‚   â”œâ”€â”€ squeezed_teeth/
â”‚   â”‚   â”œâ”€â”€ 000.png
â”‚   â”‚   â”œâ”€â”€ 001.png
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ thread/
â”‚       â”œâ”€â”€ 000.png
â”‚       â””â”€â”€ ...
â””â”€â”€ ...
```

---

## âš ï¸ ì£¼ì˜ì‚¬í•­

### 1. storage_infoëŠ” í•„ìˆ˜ í•„ë“œì…ë‹ˆë‹¤

**Phase 16.6 ì´í›„ exportëœ annotation íŒŒì¼**ì—ëŠ” í•­ìƒ `storage_info`ê°€ í¬í•¨ë©ë‹ˆë‹¤.

ë§Œì•½ `storage_info`ê°€ ì—†ëŠ” íŒŒì¼ì„ ë°›ìœ¼ë©´:
- Legacy íŒŒì¼ (Phase 16.6 ì´ì „)
- Labeler backend ë²„ì „ í™•ì¸ í•„ìš”

### 2. image_rootëŠ” í•­ìƒ `/`ë¡œ ëë‚¨

```python
# ì˜¬ë°”ë¥¸ ì‚¬ìš©
s3_key = storage_info['image_root'] + image['file_name']
# "datasets/ds_c75023ca76d7448b/images/" + "zipper/000.png"
# = "datasets/ds_c75023ca76d7448b/images/zipper/000.png"

# ì˜ëª»ëœ ì‚¬ìš© (ìŠ¬ë˜ì‹œ ì¤‘ë³µ)
s3_key = storage_info['image_root'] + '/' + image['file_name']
# "datasets/ds_c75023ca76d7448b/images/" + "/" + "zipper/000.png"
# = "datasets/ds_c75023ca76d7448b/images//zipper/000.png"  â† ìŠ¬ë˜ì‹œ ì¤‘ë³µ!
```

### 3. Cloudflare R2 ì‚¬ìš© ì‹œ endpoint ì„¤ì • í•„ìš”

```python
# R2 ì‚¬ìš© ì‹œ
s3_client = boto3.client(
    's3',
    endpoint_url='https://ACCOUNT_ID.r2.cloudflarestorage.com',  # â† í•„ìˆ˜!
    aws_access_key_id='...',
    aws_secret_access_key='...',
    region_name='auto'  # R2ëŠ” 'auto'
)

# AWS S3 ì‚¬ìš© ì‹œ
s3_client = boto3.client(
    's3',
    # endpoint_url ë¶ˆí•„ìš”
    region_name='us-east-1'
)
```

---

## â“ FAQ

### Q1: storage_infoê°€ ì—†ëŠ” annotation íŒŒì¼ì„ ë°›ìœ¼ë©´?

**A**: Phase 16.6 ì´ì „ì— exportëœ íŒŒì¼ì…ë‹ˆë‹¤.
Labeler APIì˜ `PlatformDatasetResponse`ì—ì„œ `storage_path`ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”:

```python
# Legacy ì§€ì›
if 'storage_info' not in annotation:
    # Platform API ì‘ë‹µì—ì„œ ê°€ì ¸ì˜¨ dataset ì •ë³´ ì‚¬ìš©
    storage_info = {
        'bucket': 'training-datasets',
        'image_root': f"{dataset['storage_path']}images/"
    }
```

### Q2: file_nameì— ì ˆëŒ€ ê²½ë¡œê°€ ë“¤ì–´ìˆë‚˜ìš”?

**A**: ì•„ë‹ˆìš”, í•­ìƒ **ìƒëŒ€ ê²½ë¡œ**ì…ë‹ˆë‹¤.

```json
{
  "file_name": "zipper/squeezed_teeth/000.png"  // â† ìƒëŒ€ ê²½ë¡œë§Œ
}
```

Full S3 keyëŠ” `image_root + file_name`ìœ¼ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤.

### Q3: ì—¬ëŸ¬ task_typeì˜ annotationì„ ë°›ìœ¼ë©´?

**A**: ê° task_typeë§ˆë‹¤ **ë³„ë„ì˜ annotation íŒŒì¼**ì„ ë°›ìŠµë‹ˆë‹¤.

```
dataset_id: ds_abc123

# Detection annotation
GET /api/v1/platform/datasets?task_type=detection
â†’ annotation_path: exports/.../detection/v5.0/annotations.json
â†’ storage_info.image_root: datasets/ds_abc123/images/

# Segmentation annotation
GET /api/v1/platform/datasets?task_type=segmentation
â†’ annotation_path: exports/.../segmentation/v3.0/annotations.json
â†’ storage_info.image_root: datasets/ds_abc123/images/  â† ë™ì¼!
```

**ì¤‘ìš”**: `storage_info`ëŠ” ë™ì¼í•˜ê³  (ê°™ì€ ë°ì´í„°ì…‹),
annotation ë‚´ìš©ë§Œ ë‹¤ë¦…ë‹ˆë‹¤ (taskë³„ë¡œ ë‹¤ë¥¸ annotation).

### Q4: ì´ë¯¸ì§€ê°€ ë„ˆë¬´ ë§ìœ¼ë©´?

**A**: ë³‘ë ¬ ë‹¤ìš´ë¡œë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”:

```python
from concurrent.futures import ThreadPoolExecutor

def download_image(s3_client, bucket, s3_key, local_path):
    """ë‹¨ì¼ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ"""
    local_path.parent.mkdir(parents=True, exist_ok=True)
    s3_client.download_file(Bucket=bucket, Key=s3_key, Filename=str(local_path))
    return s3_key

# ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ (10 workers)
with ThreadPoolExecutor(max_workers=10) as executor:
    futures = []
    for img in annotation['images']:
        s3_key = storage_info['image_root'] + img['file_name']
        local_path = Path(output_dir) / img['file_name']

        future = executor.submit(
            download_image,
            s3_client,
            storage_info['bucket'],
            s3_key,
            local_path
        )
        futures.append(future)

    # ì™„ë£Œ ëŒ€ê¸°
    for future in futures:
        future.result()
```

---

## ğŸ“ ë¬¸ì˜

**ê¸°ìˆ  ë¬¸ì˜**:
- Labeler Backend íŒ€: #labeler-backend (Slack)
- Annotation í˜•ì‹ ì´ìŠˆ: GitHub Issues

---

**Generated**: 2025-11-30
**Version**: Phase 16.6
**Labeler Backend**: v1.16.6
