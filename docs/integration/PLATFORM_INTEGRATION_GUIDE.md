# Platform íŒ€ - Labeler API ì—°ë™ ê°€ì´ë“œ

**ì‘ì„±ì¼**: 2025-11-30
**Phase**: 16.6 (Task-Type-Specific Dataset Query)
**ëŒ€ìƒ**: Platform Backend ê°œë°œíŒ€

---

## ğŸ“‹ ëª©ì°¨

1. [ë³€ê²½ ì‚¬í•­ ìš”ì•½](#ë³€ê²½-ì‚¬í•­-ìš”ì•½)
2. [API ì—”ë“œí¬ì¸íŠ¸ ìƒì„¸](#api-ì—”ë“œí¬ì¸íŠ¸-ìƒì„¸)
3. [task_typeë³„ í†µê³„ ë°˜í™˜ ë¡œì§](#task_typeë³„-í†µê³„-ë°˜í™˜-ë¡œì§)
4. [ì‚¬ìš© ì˜ˆì‹œ](#ì‚¬ìš©-ì˜ˆì‹œ)
5. [ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ](#ë§ˆì´ê·¸ë ˆì´ì…˜-ê°€ì´ë“œ)
6. [FAQ](#faq)

---

## ğŸ¯ ë³€ê²½ ì‚¬í•­ ìš”ì•½

### Phase 16.6: Task-Type-Specific Dataset Query

Labelerê°€ **task_typeë³„ ë°ì´í„°ì…‹ í•„í„°ë§ ë° í†µê³„ ì œê³µ** ê¸°ëŠ¥ì„ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.

#### ì£¼ìš” ë³€ê²½ì‚¬í•­

| í•­ëª© | ë³€ê²½ ì „ | ë³€ê²½ í›„ |
|------|---------|---------|
| **ë°ì´í„°ì…‹ í•„í„°ë§** | labeled=trueë§Œ ê°€ëŠ¥ | task_typeë³„ í•„í„°ë§ ê°€ëŠ¥ |
| **í†µê³„ ì •ë³´** | ì „ì²´ ë°ì´í„°ì…‹ í†µê³„ ë°˜í™˜ | task_typeë³„ í†µê³„ ë°˜í™˜ |
| **annotation_path** | ê³ ì •ëœ ê²½ë¡œ | task_typeë³„ ìµœì‹  ë²„ì „ ê²½ë¡œ |
| **ì‘ë‹µ í•„ë“œ** | - | `published_task_types` ì¶”ê°€ |

---

## ğŸ“¡ API ì—”ë“œí¬ì¸íŠ¸ ìƒì„¸

### 1. ë°ì´í„°ì…‹ ëª©ë¡ ì¡°íšŒ (List Datasets)

#### ì—”ë“œí¬ì¸íŠ¸
```
GET /api/v1/platform/datasets
```

#### ì¸ì¦
```http
Authorization: Bearer <SERVICE_JWT_TOKEN>
```

#### ìƒˆë¡œ ì¶”ê°€ëœ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„° | íƒ€ì… | í•„ìˆ˜ | ì„¤ëª… | ì˜ˆì‹œ |
|----------|------|------|------|------|
| `task_type` | string | âŒ | í•™ìŠµ task typeìœ¼ë¡œ í•„í„°ë§ | `detection`, `segmentation`, `classification` |

#### ê¸°ì¡´ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° (ë³€ê²½ ì—†ìŒ)

| íŒŒë¼ë¯¸í„° | íƒ€ì… | í•„ìˆ˜ | ì„¤ëª… |
|----------|------|------|------|
| `user_id` | integer | âŒ | Ownerë¡œ í•„í„°ë§ |
| `visibility` | string | âŒ | `public`, `private`, `organization` |
| `labeled` | boolean | âŒ | labeled ìƒíƒœë¡œ í•„í„°ë§ |
| `format` | string | âŒ | `coco`, `yolo`, `dice`, `imagefolder` |
| `page` | integer | âŒ | í˜ì´ì§€ ë²ˆí˜¸ (default: 1) |
| `limit` | integer | âŒ | í˜ì´ì§€ë‹¹ í•­ëª© ìˆ˜ (default: 50, max: 200) |

#### ì‘ë‹µ ìŠ¤í‚¤ë§ˆ ë³€ê²½

**ìƒˆë¡œ ì¶”ê°€ëœ í•„ë“œ**:

```json
{
  "datasets": [{
    ...
    "published_task_types": ["detection", "segmentation"],  // â† ìƒˆ í•„ë“œ
    ...
  }]
}
```

**ì „ì²´ ì‘ë‹µ ì˜ˆì‹œ**:

```json
{
  "total": 1,
  "page": 1,
  "limit": 50,
  "datasets": [
    {
      "id": "ds_c75023ca76d7448b",
      "name": "mvtec-ad",
      "description": "MVTec Anomaly Detection Dataset",
      "format": "coco",
      "labeled": true,
      "storage_type": "r2",
      "storage_path": "datasets/ds_c75023ca76d7448b",
      "annotation_path": "exports/proj_026c67eeafb4/detection/v10.0/annotations.json",

      // í†µê³„ ì •ë³´ (task_typeë³„ë¡œ ë‹¬ë¼ì§!)
      "num_classes": null,
      "num_images": 163,  // â† task_type='detection' ì§€ì • ì‹œ: 163ê°œ
                          // â† task_type ë¯¸ì§€ì • ì‹œ: 1725ê°œ (ì „ì²´)
      "class_names": null,

      // Phase 16.6 ì¶”ê°€ í•„ë“œ
      "published_task_types": ["detection"],  // â† ì–´ë–¤ task_typeìœ¼ë¡œ publish ë˜ì—ˆëŠ”ì§€

      // ë©”íƒ€ë°ì´í„°
      "tags": ["anomaly-detection", "industrial"],
      "visibility": "public",
      "owner_id": 1,
      "version": 10,
      "content_hash": "abc123...",
      "created_at": "2025-11-25T10:00:00",
      "updated_at": "2025-11-26T15:30:00"
    }
  ]
}
```

---

## ğŸ” task_typeë³„ í†µê³„ ë°˜í™˜ ë¡œì§

### âš ï¸ ì¤‘ìš”: í†µê³„ ì •ë³´ëŠ” task_typeì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤!

#### Case 1: `task_type` íŒŒë¼ë¯¸í„° ì œê³µ (ê¶Œì¥)

```http
GET /api/v1/platform/datasets?task_type=detection&labeled=true
```

**ë°˜í™˜ í†µê³„**: í•´ë‹¹ task_typeì˜ **ìµœì‹  AnnotationVersion í†µê³„**

| í•„ë“œ | ê°’ | ì„¤ëª… |
|------|-----|------|
| `num_images` | 163 | **detection taskì—ì„œ annotateëœ ì´ë¯¸ì§€ ìˆ˜** |
| `annotation_path` | `exports/.../detection/v10.0/annotations.json` | **detection taskì˜ ìµœì‹  export ê²½ë¡œ** |
| `published_task_types` | `["detection"]` | ì´ ë°ì´í„°ì…‹ì´ publishëœ task type ëª©ë¡ |

**í•™ìŠµì— ì‚¬ìš©í•  ì •í™•í•œ ë°ì´í„°**:
- ì´ë¯¸ì§€: 163ê°œ
- Annotation íŒŒì¼: `exports/proj_026c67eeafb4/detection/v10.0/annotations.json`

---

#### Case 2: `task_type` íŒŒë¼ë¯¸í„° ë¯¸ì œê³µ

```http
GET /api/v1/platform/datasets?labeled=true
```

**ë°˜í™˜ í†µê³„**: ì „ì²´ ë°ì´í„°ì…‹ì˜ **Dataset í…Œì´ë¸” í†µê³„**

| í•„ë“œ | ê°’ | ì„¤ëª… |
|------|-----|------|
| `num_images` | 1725 | **ë°ì´í„°ì…‹ì˜ ì „ì²´ ì´ë¯¸ì§€ ìˆ˜** |
| `annotation_path` | `datasets/.../annotations_detection.json` | ë°ì´í„°ì…‹ ë ˆë²¨ annotation ê²½ë¡œ (ì°¸ê³ ìš©) |
| `published_task_types` | `["detection"]` | ì´ ë°ì´í„°ì…‹ì´ publishëœ task type ëª©ë¡ |

âš ï¸ **ì£¼ì˜**: ì „ì²´ í†µê³„ì´ë¯€ë¡œ í•™ìŠµì— ì§ì ‘ ì‚¬ìš©í•˜ê¸° ë¶€ì í•©!

---

### ì˜ˆì‹œ ì‹œë‚˜ë¦¬ì˜¤

#### ì‹œë‚˜ë¦¬ì˜¤ 1: mvtec-ad ë°ì´í„°ì…‹

**ë°ì´í„°ì…‹ êµ¬ì„±**:
- ì „ì²´ ì´ë¯¸ì§€: 1,725ê°œ
- detectionìœ¼ë¡œ publish: 163ê°œ ì´ë¯¸ì§€, 241ê°œ annotation (v10.0)
- segmentationìœ¼ë¡œ publish: ì•ˆ ë¨
- classificationìœ¼ë¡œ publish: ì•ˆ ë¨

**Platform íŒ€ì˜ ìš”ì²­ë³„ ì‘ë‹µ**:

| Platform ìš”ì²­ | ë°˜í™˜ ë°ì´í„°ì…‹ ìˆ˜ | num_images | annotation_path |
|---------------|------------------|------------|-----------------|
| `task_type=detection` | 1ê°œ (mvtec-ad) | **163** | `exports/.../detection/v10.0/...` |
| `task_type=segmentation` | 0ê°œ | - | - |
| `task_type=classification` | 0ê°œ | - | - |
| `task_type` ë¯¸ì§€ì • | 1ê°œ (mvtec-ad) | **1725** | `datasets/.../annotations_detection.json` |

---

#### ì‹œë‚˜ë¦¬ì˜¤ 2: multi-task ë°ì´í„°ì…‹ (ê°€ì •)

**ë°ì´í„°ì…‹ êµ¬ì„±**:
- ì „ì²´ ì´ë¯¸ì§€: 5,000ê°œ
- detectionìœ¼ë¡œ publish: 3,200ê°œ ì´ë¯¸ì§€ (v5.0)
- segmentationìœ¼ë¡œ publish: 1,800ê°œ ì´ë¯¸ì§€ (v3.0)
- classificationìœ¼ë¡œ publish: 4,500ê°œ ì´ë¯¸ì§€ (v2.0)

**Platform íŒ€ì˜ ìš”ì²­ë³„ ì‘ë‹µ**:

| Platform ìš”ì²­ | num_images | annotation_path |
|---------------|------------|-----------------|
| `task_type=detection` | **3,200** | `exports/.../detection/v5.0/...` |
| `task_type=segmentation` | **1,800** | `exports/.../segmentation/v3.0/...` |
| `task_type=classification` | **4,500** | `exports/.../classification/v2.0/...` |
| `task_type` ë¯¸ì§€ì • | **5,000** | `datasets/.../...` (ì „ì²´) |

---

## ğŸ’¡ ì‚¬ìš© ì˜ˆì‹œ

### Python ì½”ë“œ ì˜ˆì‹œ (Platform Backend)

```python
import requests
import jwt
from datetime import datetime, timedelta

# 1. Service JWT ìƒì„±
SERVICE_JWT_SECRET = "8f7e6d5c4b3a29180716253e4f5a6b7c8d9e0f1a2b3c4d5e6f7a8b9c0d1e2f3a"

def create_service_jwt(user_id: int) -> str:
    """Platformì—ì„œ Labeler API í˜¸ì¶œìš© JWT ìƒì„±"""
    payload = {
        "sub": str(user_id),  # ì‚¬ìš©ì ID
        "service": "platform",
        "scopes": ["labeler:read"],
        "type": "service",
        "iat": datetime.utcnow(),
        "exp": datetime.utcnow() + timedelta(minutes=5),
    }
    return jwt.encode(payload, SERVICE_JWT_SECRET, algorithm="HS256")


# 2. Detection ëª¨ë¸ í•™ìŠµìš© ë°ì´í„°ì…‹ ì¡°íšŒ
def get_datasets_for_detection_training(user_id: int):
    """Detection ëª¨ë¸ í•™ìŠµì— ì‚¬ìš©í•  ë°ì´í„°ì…‹ ëª©ë¡ ì¡°íšŒ"""

    token = create_service_jwt(user_id)

    response = requests.get(
        "http://labeler-backend:8000/api/v1/platform/datasets",
        headers={"Authorization": f"Bearer {token}"},
        params={
            "task_type": "detection",  # â† ì¤‘ìš”!
            "labeled": True,
            "limit": 100,
        }
    )

    if response.status_code != 200:
        raise Exception(f"Failed to fetch datasets: {response.text}")

    data = response.json()

    for dataset in data["datasets"]:
        print(f"Dataset: {dataset['name']}")
        print(f"  - Images: {dataset['num_images']}")  # detection task ì´ë¯¸ì§€ ìˆ˜
        print(f"  - Annotation: {dataset['annotation_path']}")  # detection annotation ê²½ë¡œ
        print(f"  - Published tasks: {dataset['published_task_types']}")
        print()

    return data["datasets"]


# 3. íŠ¹ì • ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµ Job ìƒì„±
def create_training_job(user_id: int, dataset_id: str, task_type: str):
    """í•™ìŠµ Job ìƒì„±"""

    # 1ë‹¨ê³„: ë°ì´í„°ì…‹ ì •ë³´ ì¡°íšŒ (task_typeë³„ í†µê³„ í¬í•¨)
    token = create_service_jwt(user_id)

    response = requests.get(
        f"http://labeler-backend:8000/api/v1/platform/datasets",
        headers={"Authorization": f"Bearer {token}"},
        params={"task_type": task_type}
    )

    datasets = response.json()["datasets"]
    dataset = next((d for d in datasets if d["id"] == dataset_id), None)

    if not dataset:
        raise Exception(f"Dataset {dataset_id} not found or not published for {task_type}")

    # 2ë‹¨ê³„: task_typeë³„ ì •í™•í•œ í†µê³„ í™•ì¸
    print(f"Creating training job:")
    print(f"  - Dataset: {dataset['name']}")
    print(f"  - Task: {task_type}")
    print(f"  - Images: {dataset['num_images']}")  # task_typeë³„ ì´ë¯¸ì§€ ìˆ˜
    print(f"  - Annotation path: {dataset['annotation_path']}")  # task_typeë³„ ê²½ë¡œ

    # 3ë‹¨ê³„: í•™ìŠµ Job ìƒì„± (Platform ë‚´ë¶€ ë¡œì§)
    training_job = {
        "dataset_id": dataset_id,
        "task_type": task_type,
        "num_images": dataset["num_images"],
        "annotation_path": dataset["annotation_path"],
        # ... ê¸°íƒ€ í•™ìŠµ ì„¤ì •
    }

    return training_job


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    user_id = 1  # admin@example.com

    # Detection ëª¨ë¸ í•™ìŠµìš© ë°ì´í„°ì…‹ ì¡°íšŒ
    print("=" * 80)
    print("Detection ëª¨ë¸ í•™ìŠµìš© ë°ì´í„°ì…‹ ì¡°íšŒ")
    print("=" * 80)
    datasets = get_datasets_for_detection_training(user_id)

    # í•™ìŠµ Job ìƒì„±
    if datasets:
        print("\n" + "=" * 80)
        print("í•™ìŠµ Job ìƒì„±")
        print("=" * 80)
        job = create_training_job(
            user_id=user_id,
            dataset_id=datasets[0]["id"],
            task_type="detection"
        )
```

---

## ğŸ”„ ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ

### Platform Backend ìˆ˜ì • ì‚¬í•­

#### 1. API ìš”ì²­ ì‹œ `task_type` íŒŒë¼ë¯¸í„° ì¶”ê°€

**ë³€ê²½ ì „**:
```python
response = requests.get(
    f"{LABELER_API}/platform/datasets",
    params={"labeled": True}
)
```

**ë³€ê²½ í›„**:
```python
response = requests.get(
    f"{LABELER_API}/platform/datasets",
    params={
        "labeled": True,
        "task_type": training_job.task_type  # â† ì¶”ê°€!
    }
)
```

---

#### 2. ì‘ë‹µ ìŠ¤í‚¤ë§ˆì— `published_task_types` í•„ë“œ ì¶”ê°€

**Platformì˜ Dataset ëª¨ë¸** (Pydantic ë˜ëŠ” TypeScript):

```python
class LabelerDatasetResponse(BaseModel):
    id: str
    name: str
    ...
    num_images: int
    published_task_types: List[str]  # â† ìƒˆ í•„ë“œ ì¶”ê°€
    ...
```

```typescript
// TypeScript
interface LabelerDataset {
  id: string;
  name: string;
  ...
  num_images: number;
  published_task_types: string[];  // â† ìƒˆ í•„ë“œ ì¶”ê°€
  ...
}
```

---

#### 3. ê²€ì¦ ë¡œì§ ì¶”ê°€

```python
def validate_dataset_for_training(dataset: dict, task_type: str):
    """ë°ì´í„°ì…‹ì´ íŠ¹ì • task_typeìœ¼ë¡œ í•™ìŠµ ê°€ëŠ¥í•œì§€ ê²€ì¦"""

    # Check 1: task_typeì´ publishë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    if task_type not in dataset["published_task_types"]:
        raise ValueError(
            f"Dataset {dataset['name']} is not published for {task_type}. "
            f"Available: {dataset['published_task_types']}"
        )

    # Check 2: ì¶©ë¶„í•œ ì´ë¯¸ì§€ê°€ ìˆëŠ”ì§€ í™•ì¸
    if dataset["num_images"] < 10:
        raise ValueError(
            f"Dataset {dataset['name']} has only {dataset['num_images']} images "
            f"for {task_type}, minimum 10 required"
        )

    # Check 3: annotation_pathê°€ ìˆëŠ”ì§€ í™•ì¸
    if not dataset["annotation_path"]:
        raise ValueError(
            f"Dataset {dataset['name']} has no annotation file for {task_type}"
        )

    return True
```

---

## â“ FAQ

### Q1: task_typeì„ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?

A: ì „ì²´ ë°ì´í„°ì…‹ í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ **í•™ìŠµì— ì‚¬ìš©í•˜ê¸°ì—ëŠ” ë¶€ì í•©**í•©ë‹ˆë‹¤.

**ì˜ˆì‹œ**:
- ìš”ì²­: `GET /api/v1/platform/datasets?labeled=true` (task_type ì—†ìŒ)
- ì‘ë‹µ: `num_images=1725` (ì „ì²´ ì´ë¯¸ì§€ ìˆ˜)
- ë¬¸ì œ: detection taskëŠ” ì‹¤ì œë¡œ 163ê°œ ì´ë¯¸ì§€ë§Œ ìˆìŒ!

**ê¶Œì¥**: í•­ìƒ `task_type` íŒŒë¼ë¯¸í„°ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.

---

### Q2: í•˜ë‚˜ì˜ ë°ì´í„°ì…‹ì„ ì—¬ëŸ¬ task_typeìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë‚˜ìš”?

A: **ë„¤, ê°€ëŠ¥í•©ë‹ˆë‹¤.**

í•˜ë‚˜ì˜ ë°ì´í„°ì…‹ì´ detection, segmentation, classification ëª¨ë‘ë¡œ publishë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ì˜ˆì‹œ**:
```json
{
  "id": "ds_multi_task",
  "name": "Multi-Task Dataset",
  "published_task_types": ["detection", "segmentation", "classification"],
  ...
}
```

**ê° task_typeë³„ë¡œ ì¡°íšŒí•˜ë©´ ë‹¤ë¥¸ í†µê³„ê°€ ë°˜í™˜ë©ë‹ˆë‹¤**:
- `task_type=detection` â†’ 3,200ê°œ ì´ë¯¸ì§€
- `task_type=segmentation` â†’ 1,800ê°œ ì´ë¯¸ì§€
- `task_type=classification` â†’ 4,500ê°œ ì´ë¯¸ì§€

---

### Q3: published_task_typesê°€ ë¹ˆ ë°°ì—´ì´ë©´?

A: í•´ë‹¹ ë°ì´í„°ì…‹ì€ **ì•„ì§ publishë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤**.

```json
{
  "id": "ds_unpublished",
  "name": "Work in Progress",
  "labeled": false,
  "published_task_types": [],  // â† ë¹ˆ ë°°ì—´
  ...
}
```

**ê¶Œì¥**: `labeled=true`ì™€ `task_type` í•„í„°ë¥¼ í•¨ê»˜ ì‚¬ìš©í•˜ë©´ publishëœ ë°ì´í„°ì…‹ë§Œ ì¡°íšŒë©ë‹ˆë‹¤.

---

### Q4: annotation_pathëŠ” ì–´ë–»ê²Œ ì‚¬ìš©í•˜ë‚˜ìš”?

A: **task_typeë³„ ìµœì‹  annotation íŒŒì¼ ê²½ë¡œ**ì…ë‹ˆë‹¤.

**ê²½ë¡œ êµ¬ì¡°**:
```
exports/{project_id}/{task_type}/{version}/annotations.json
```

**ì˜ˆì‹œ**:
```
exports/proj_026c67eeafb4/detection/v10.0/annotations.json
```

**S3/R2ì—ì„œ ë‹¤ìš´ë¡œë“œ**:
```python
# Labelerì˜ R2 ë²„í‚·ì—ì„œ ë‹¤ìš´ë¡œë“œ
s3_key = dataset["annotation_path"]
annotation_url = storage_client.generate_presigned_url(
    bucket="training-datasets",
    key=s3_key,
    expiration=3600
)
```

ë˜ëŠ” **Labeler APIì˜ download-url ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©**:
```python
# Labeler APIë¥¼ í†µí•´ presigned URL ë°›ê¸° (ê¶Œì¥)
response = requests.post(
    f"{LABELER_API}/platform/datasets/{dataset_id}/download-url",
    headers={"Authorization": f"Bearer {token}"},
    json={"expiration_seconds": 3600}
)
download_url = response.json()["download_url"]
```

---

### Q5: num_classesì™€ class_namesëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?

A: í˜„ì¬ ë²„ì „ì—ì„œëŠ” **ë°ì´í„°ì…‹ ë ˆë²¨ í†µê³„**ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

**í–¥í›„ ê°œì„  ì˜ˆì •**:
- task_typeë³„ class ì •ë³´ ì¶”ì¶œ
- annotation íŒŒì¼ì—ì„œ class ëª©ë¡ íŒŒì‹±

**í˜„ì¬ ìš°ì„  ìˆœìœ„**:
1. âœ… task_typeë³„ í•„í„°ë§
2. âœ… task_typeë³„ ì´ë¯¸ì§€ ìˆ˜ (`num_images`)
3. âœ… task_typeë³„ annotation ê²½ë¡œ (`annotation_path`)
4. â³ task_typeë³„ í´ë˜ìŠ¤ ì •ë³´ (`num_classes`, `class_names`) - í–¥í›„ ì¶”ê°€

---

### Q6: ê¸°ì¡´ ì½”ë“œì™€ í˜¸í™˜ë˜ë‚˜ìš”?

A: **ë„¤, 100% í˜¸í™˜ë©ë‹ˆë‹¤.**

**Backward Compatibility**:
- `task_type` íŒŒë¼ë¯¸í„°ëŠ” **optional**
- ê¸°ì¡´ ìš”ì²­ì€ ê·¸ëŒ€ë¡œ ì‘ë™ (Dataset ë ˆë²¨ í†µê³„ ë°˜í™˜)
- ìƒˆ í•„ë“œ `published_task_types`ëŠ” ë¹ˆ ë°°ì—´ ë˜ëŠ” ê°’ ë°˜í™˜

**ê¶Œì¥ ë§ˆì´ê·¸ë ˆì´ì…˜**:
1. Phase 1: `published_task_types` í•„ë“œë¥¼ ì‘ë‹µ ìŠ¤í‚¤ë§ˆì— ì¶”ê°€ (ë¬´ì‹œí•´ë„ ë¨)
2. Phase 2: `task_type` íŒŒë¼ë¯¸í„° ì‚¬ìš© ì‹œì‘
3. Phase 3: ê²€ì¦ ë¡œì§ ì¶”ê°€ (`published_task_types` í™•ì¸)

---

### Q7: ì„±ëŠ¥ì€ ì–´ë–¤ê°€ìš”?

A: **ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.**

**ì¸ë±ìŠ¤**:
- `published_task_types`: PostgreSQL GIN index (array containment ìµœì í™”)
- `task_type`: AnnotationVersion í…Œì´ë¸” ì¸ë±ìŠ¤

**ì¿¼ë¦¬ ì„±ëŠ¥**:
- task_type í•„í„°ë§: ~5ms (GIN index ì‚¬ìš©)
- AnnotationVersion ì¡°íšŒ: ~2ms (ì¸ë±ìŠ¤ ì‚¬ìš©)

**ëŒ€ê·œëª¨ ë°ì´í„°ì…‹** (10,000+ datasets):
- í˜ì´ì§€ë„¤ì´ì…˜ ì§€ì› (`limit`, `page`)
- ìµœëŒ€ 200ê°œ/í˜ì´ì§€

---

## ğŸ“ ë¬¸ì˜

**ê¸°ìˆ  ë¬¸ì˜**:
- Labeler Backend íŒ€: #labeler-backend (Slack)
- API ì´ìŠˆ: GitHub Issues

**ê¸´ê¸‰ ë¬¸ì˜**:
- On-call: Labeler DevOps íŒ€

---

## ğŸ“Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

Platform íŒ€ì´ í™•ì¸í•´ì•¼ í•  ì‚¬í•­:

- [ ] `task_type` ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì¶”ê°€
- [ ] `published_task_types` í•„ë“œë¥¼ ì‘ë‹µ ìŠ¤í‚¤ë§ˆì— ì¶”ê°€
- [ ] task_type ê²€ì¦ ë¡œì§ êµ¬í˜„
- [ ] ê¸°ì¡´ í•™ìŠµ Jobì´ ì˜¬ë°”ë¥¸ í†µê³„ë¥¼ ì‚¬ìš©í•˜ëŠ”ì§€ í™•ì¸
- [ ] í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‘ì„± (task_typeë³„ ì¡°íšŒ)
- [ ] ë¬¸ì„œ ì—…ë°ì´íŠ¸ (Platform ë‚´ë¶€ ë¬¸ì„œ)

---

**Generated**: 2025-11-30
**Version**: Phase 16.6
**Labeler Backend**: v1.16.6
